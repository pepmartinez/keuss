"use strict";(self.webpackChunkkeuss_docusaurus=self.webpackChunkkeuss_docusaurus||[]).push([[4064],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>d});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),u=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},p=function(e){var t=u(e.components);return r.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=u(n),d=o,g=c["".concat(l,".").concat(d)]||c[d]||m[d]||a;return n?r.createElement(g,s(s({ref:t},p),{},{components:n})):r.createElement(g,s({ref:t},p))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,s=new Array(a);s[0]=c;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:o,s[1]=i;for(var u=2;u<a;u++)s[u]=n[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}c.displayName="MDXCreateElement"},5345:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>a,metadata:()=>i,toc:()=>u});var r=n(7462),o=(n(7294),n(3905));const a={id:"stream-mongo",title:"Stream-mongo backend",sidebar_label:"Stream-mongo backend"},s=void 0,i={unversionedId:"Usage/Streaming/stream-mongo",id:"Usage/Streaming/stream-mongo",title:"Stream-mongo backend",description:"stream-mongo is the result of a series of experiments to find out if implementing event streaming on top of mongodb with a",source:"@site/docs/04-Usage/07-Streaming/01-stream-mongo.md",sourceDirName:"04-Usage/07-Streaming",slug:"/Usage/Streaming/stream-mongo",permalink:"/keuss/docs/Usage/Streaming/stream-mongo",draft:!1,editUrl:"https://github.com/pepmartinez/keuss/edit/master/website/docs/04-Usage/07-Streaming/01-stream-mongo.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"stream-mongo",title:"Stream-mongo backend",sidebar_label:"Stream-mongo backend"},sidebar:"tutorialSidebar",previous:{title:"Examples",permalink:"/keuss/docs/Usage/Pipelines/examples"},next:{title:"Map of Strict Ordered Queues",permalink:"/keuss/docs/Usage/Experiments-and-Curiosities/map-of-strict-ordered-queues"}},l={},u=[{value:"Creation options",id:"creation-options",level:2},{value:"Usage",id:"usage",level:2},{value:"Extra stats",id:"extra-stats",level:2},{value:"Limitations",id:"limitations",level:2}],p={toc:u};function m(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"stream-mongo")," is the result of a series of experiments to find out if implementing event streaming on top of mongodb with a\nsimilar set of features that those offered by the likes of ",(0,o.kt)("inlineCode",{parentName:"p"},"kafka")," is, indeed, viable. "),(0,o.kt)("p",null,"One key feature is the concept of ",(0,o.kt)("inlineCode",{parentName:"p"},"consumer groups"),": in short, consumers can identify themselves as part of a group (a label)\nso it is guaranteed that each event/message will be consumed exactly by one consumer in each group. This is crucial for\ncorrect LB/HA and scalability without the need for complex logic or locks in the consumers"),(0,o.kt)("p",null,"There seems to be no such actual implementation out there, and the early tests on the obvious ways were all a dead end:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"using a capped collection is OK for a general pub/sub with some history/replay capabilities, but it seems impossible to\ncorrectly manage consumer groups"),(0,o.kt)("li",{parentName:"ul"},"using a regular collection also proved impossible to manage consumer groups in a general case: logic quickly turns\nexcessively complex and performance quickly degrades with a few groups"),(0,o.kt)("li",{parentName:"ul"},"using more than one collection (one for data, one for group management) can't be correctly done without race conditions")),(0,o.kt)("p",null,"A slightly different approach was tried: provide a small, predefined set of consumer groups. In most practical cases events\non each topic are in fact read by a (very) small set of consumer groups, and they do not change often either. So, this approximation\nmight be a good compromise "),(0,o.kt)("p",null,"The resulting implementation is just an extension of ",(0,o.kt)("inlineCode",{parentName:"p"},"ps-mongo"),", where elements consumed are not deleted but marked. Instead of a single 'consume marker', a set of them is added on each pushed element, where each marker represents a consumer group. The marker set and therefore the possible consumer groups of an element are defined by the Queue instance performing the push operation, and several Queues can push to the same queue using different sets. Performance is almost the same than that of ",(0,o.kt)("inlineCode",{parentName:"p"},"ps-mongo"),", with a slightly bigger index usage (each group has its own, separated index created)"),(0,o.kt)("p",null,"The 'consumer markers' also provide all the machinery to do reserve-commit-rollback, and also scheduling. Each consumer group will get its own separated logic and state for reserve-commit-rollback, and retries/scheduling"),(0,o.kt)("h2",{id:"creation-options"},"Creation options"),(0,o.kt)("p",null,"Creation of a Queue with backend ",(0,o.kt)("inlineCode",{parentName:"p"},"stream-mongo")," takes 2 specific options:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"ttl"),": time to keep consumed elements in the collection after being removed. Defaults to 3600 secs."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"groups"),": string, comma-separated list of possible consumer groups to be used on push operations. Defaults to ",(0,o.kt)("inlineCode",{parentName:"li"},"A,B,C")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"group"),": string, consumer group to be used on pop/reserve operations. Defaults to first element of ",(0,o.kt)("inlineCode",{parentName:"li"},"groups"))),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"ttl")," is shared with ",(0,o.kt)("inlineCode",{parentName:"p"},"ps-mongo")," backend and is used to create a TTL index to delete elements from the collection, so they don't get stored forever. Therefore, storage limitation is done by time, not by space or number of elements"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"groups")," defines the possible consumer groups each subsequent inserted element would be addressed to (more on that later)"),(0,o.kt)("h2",{id:"usage"},"Usage"),(0,o.kt)("p",null,"In short, a ",(0,o.kt)("inlineCode",{parentName:"p"},"stream-mongo")," queue works by attaching a separated 'consumed marker' per each possible consumer group (defined at the queue option ",(0,o.kt)("inlineCode",{parentName:"p"},"groups"),") at push time, and later specifying the desired consumer group at pop/reserve time (defined at queue option ",(0,o.kt)("inlineCode",{parentName:"p"},"group"),"); a pop/reserve operation can only act on elements which have a 'consumer marker' for the group specified, and the set of groups of each element is defined by the options.groups of the Queue instance doing the push operation"),(0,o.kt)("p",null,"Let's see an example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"const async = require ('async');\nconst MQ =    require ('../../backends/stream-mongo');\n\n// initialize factory\nMQ ({url: 'mongodb://localhost/keuss_test_stream'}, (err, factory) => {\n  if (err) return console.error(err);\n\n  async.parallel ({\n    // producer: possible consumer groups are G1, G2 and G4, on top of collection test_stream\n    q0: cb => factory.queue ('test_stream', {groups: 'G1, G2, G4'}, cb)\n\n    // first consumer, using consumer group G1\n    q1: cb => factory.queue ('test_stream', {group: 'G1'}, cb),\n\n    // second consumer, using consumer group G2\n    q2: cb => factory.queue ('test_stream', {group: 'G2'}, cb),\n  }, (err, queues) => {\n    if (err) return console.error(err);\n\n    // let's roll\n    async.series ([\n      // push element\n      cb => queues.q0.push ({a: 1}, cb),\n      cb => setTimeout (cb, 1000),  // wait a bit\n      cb => queues.q1.pop ('consumer-1', cb), // pop element in group G1\n      cb => queues.q2.pop ('consumer-2', cb), // pop element in group G2\n    ], (err, res) => {\n      console.log ('element popped for group G1:', res[2]);\n      console.log ('element popped for group G2:', res[3]);\n\n      factory.close ();\n    });\n  });\n});\n")),(0,o.kt)("p",null,"Both q1 and q2 will get the same element, inserted by q0. If we change the code a bit:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"async.parallel ({\n  q0:    cb => factory.queue ('test_stream', {groups: 'G1, G2, G4'}, cb),\n  q1:    cb => factory.queue ('test_stream', {group: 'G1'}, cb),\n  q2:    cb => factory.queue ('test_stream', {group: 'G2'}, cb),\n  q2bis: cb => factory.queue ('test_stream', {group: 'G2'}, cb),\n  q3:    cb => factory.queue ('test_stream', {group: 'G3'}, cb),\n}, (err, queues) => {\n  if (err) return console.error(err);\n\n  async.parallel ([\n    cb => setTimeout (() => queues.q0.push ({a: 1}, cb), 1000), // delay push by a second so all consumers are ready\n    cb => queues.q1.pop ('consumer-1', cb),\n    cb => queues.q2.pop ('consumer-2', cb),\n    cb => queues.q2bis.pop ('consumer-2', cb),\n    cb => queues.q3.pop ('consumer-2', cb),\n  ], (err, res) => {\n    ...\n  });\n});\n")),(0,o.kt)("p",null,"In this situation:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"q1 would get the message"),(0,o.kt)("li",{parentName:"ul"},"either q2 or q2bis (exactly one of them) would get a copy too; the other would block forever"),(0,o.kt)("li",{parentName:"ul"},"q3 would not get a message and would block forever")),(0,o.kt)("h2",{id:"extra-stats"},"Extra stats"),(0,o.kt)("p",null,"Queues of type ",(0,o.kt)("inlineCode",{parentName:"p"},"stream-mongo")," generate extra stats, besides the standard ones:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"stream.<group>.put"),": number of elements pushed, per consumer group (a single push will increment the counter for all\ngroups defined for the queue)"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"stream.<group>.get"),":  number of elements got, per consumer group"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"stream.<group>.reserve"),":  number of elements reserved, per consumer group"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"stream.<group>.commit"),":  number of elements committed, per consumer group"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"stream.<group>.rollback"),":  number of elements rolled back, per consumer group")),(0,o.kt)("h2",{id:"limitations"},"Limitations"),(0,o.kt)("p",null,"There are a few minor limitations & glitches in ",(0,o.kt)("inlineCode",{parentName:"p"},"stream-mongo"),", besides the obvious one about not being able to use an unlimited set of possible consumer groups:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"indexes: each possible consumer group in a queue carries the creation of a separated index on the mongodb collection,\nso be aware of the potential impact on space usage and performance "),(0,o.kt)("li",{parentName:"ul"},"default stats: default queue stats (put, get, reserve...) are no longer meaningful. They still get recorded, though"),(0,o.kt)("li",{parentName:"ul"},"no delete: as it happens in a full-fledged stream system, deleting an item has no meaning. therefore, it is not implemented"),(0,o.kt)("li",{parentName:"ul"},"arbitrary defaults to groups and group: the fact that the default for groups is 'A,B,C' and the default for group is 'A' might\nseem arbitrary; it is just a set of values that make a default queue of ",(0,o.kt)("inlineCode",{parentName:"li"},"stream-mongo")," work as a replacement for ",(0,o.kt)("inlineCode",{parentName:"li"},"ps-mongo"),",\njust for coherency (except for the delete operation)")))}m.isMDXComponent=!0}}]);