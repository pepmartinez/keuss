"use strict";(self.webpackChunkkeuss_docusaurus=self.webpackChunkkeuss_docusaurus||[]).push([[7330],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>c});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),u=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=u(n),c=o,h=d["".concat(l,".").concat(c)]||d[c]||m[c]||i;return n?a.createElement(h,r(r({ref:t},p),{},{components:n})):a.createElement(h,r({ref:t},p))}));function c(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,r[1]=s;for(var u=2;u<i;u++)r[u]=n[u];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},2463:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>u});var a=n(7462),o=(n(7294),n(3905));const i={title:"Modelling queues on MongoDB - I",author:"Pep Martinez",author_url:"https://github.com/pepmartinez",tags:["mongodb","tech"]},r=void 0,s={permalink:"/keuss/blog/2024/01/22/queues-on-mongo-part-1",editUrl:"https://github.com/pepmartinez/keuss/edit/master/website/blog/blog/2024-01-22-queues-on-mongo-part-1.md",source:"@site/blog/2024-01-22-queues-on-mongo-part-1.md",title:"Modelling queues on MongoDB - I",description:"This is a series of articles describing the technical details on which keuss is based to build a rather complete",date:"2024-01-22T00:00:00.000Z",formattedDate:"January 22, 2024",tags:[{label:"mongodb",permalink:"/keuss/blog/tags/mongodb"},{label:"tech",permalink:"/keuss/blog/tags/tech"}],readingTime:17.465,hasTruncateMarker:!1,authors:[{name:"Pep Martinez",url:"https://github.com/pepmartinez"}],frontMatter:{title:"Modelling queues on MongoDB - I",author:"Pep Martinez",author_url:"https://github.com/pepmartinez",tags:["mongodb","tech"]},prevItem:{title:"Modelling queues on MongoDB - II",permalink:"/keuss/blog/2024/01/23/queues-on-mongo-part-2"},nextItem:{title:"New website!",permalink:"/keuss/blog/2020/08/04/welcome"}},l={authorsImageUrls:[void 0]},u=[{value:"Some nomenclature",id:"some-nomenclature",level:2},{value:"Basic building blocks",id:"basic-building-blocks",level:2},{value:"The need for atomic operations",id:"the-need-for-atomic-operations",level:2},{value:"Simple approach: good enough queues",id:"simple-approach-good-enough-queues",level:2},{value:"Adding an event bus",id:"adding-an-event-bus",level:2},{value:"Possible implementations",id:"possible-implementations",level:3},{value:"In-memory pub/sub",id:"in-memory-pubsub",level:4},{value:"Redis pub/sub",id:"redis-pubsub",level:4},{value:"MongoDB capped collection (also a pub/sub)",id:"mongodb-capped-collection-also-a-pubsub",level:4},{value:"Practical considerations &amp; improvements",id:"practical-considerations--improvements",level:3},{value:"Race conditions",id:"race-conditions",level:4},{value:"High cardinality of events",id:"high-cardinality-of-events",level:4},{value:"Drawbacks",id:"drawbacks",level:5},{value:"Adding another pub/sub implementation",id:"adding-another-pubsub-implementation",level:4},{value:"Final thoughts",id:"final-thoughts",level:3}],p={toc:u};function m(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"This is a series of articles describing the technical details on which ",(0,o.kt)("inlineCode",{parentName:"p"},"keuss")," is based to build a rather complete\nqueue middleware (",(0,o.kt)("inlineCode",{parentName:"p"},"QMW")," henceforth) with a quite shallow layer on top of ",(0,o.kt)("inlineCode",{parentName:"p"},"MongoDB"),". The basic approach is well known and understood, but\n",(0,o.kt)("inlineCode",{parentName:"p"},"keuss")," goes well beyond the basic approach to provide extra functionalities"),(0,o.kt)("h2",{id:"some-nomenclature"},"Some nomenclature"),(0,o.kt)("p",null,"Let us start establishing some common nomenclature that will appear later on:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"job queue")),": A construct where elements can be inserted and extracted, in a FIFO (first in, first out) manner. Elements\nextracted are removed from the queue and are no longer available")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"queue middleware (qmw)")),": A system that provides queues and means for actors to perform as producers, consumers or both")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"push")),": action of inserting an element into a queue")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"pop")),": action of extracting an element from a queue")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"reserve/commit/rollback")),": operations to provide more control on the extraction of elements: first the element is ",(0,o.kt)("em",{parentName:"p"},"reserved"),",\n(making it invisible by other reserve or pop operations, but still present in the queue), then once the element is processed it is ",(0,o.kt)("em",{parentName:"p"},"committed")," (and only then the element is removed from the queue) or ",(0,o.kt)("em",{parentName:"p"},"rolledback")," (meaning it is made elligible again for other reserve or pop, possibly after some delay); if none of ",(0,o.kt)("em",{parentName:"p"},"commit")," or ",(0,o.kt)("em",{parentName:"p"},"rollback")," happen after some time, an automatic ",(0,o.kt)("em",{parentName:"p"},"rollback")," is applied.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"consumer")),": an actor performing pop and/or reserve-commit-rollback operations on a queue. A queue can have zero or more concurrent consumers")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"producer")),": an actor performing push operations on a queue. A queue can have zero or more concurrent producers")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"at-most-once")),": consumer guarantee associated with the ",(0,o.kt)("inlineCode",{parentName:"p"},"pop")," operation: since the element is first removed from the queue, and\nthen the consumer proceeds to process it, if the consumer dies or crashes in between the element will be lost. That is, losses are\ntolerated, but duplications are not"),(0,o.kt)("mermaid",{parentName:"li",value:"sequenceDiagram\n  autonumber\n  participant queue\n  participant consumer\n  consumer->>+queue: pop\n  queue->>-consumer: element\n  activate consumer\n  note left of queue: element is no longer in queue\n  note right of consumer: process element\n  deactivate consumer\n  note right of consumer: element processed, get another\n  consumer->>+queue: pop\n  queue->>-consumer: element\n  "})),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"at-least-once")),": consumer guarantee associated with the ",(0,o.kt)("inlineCode",{parentName:"p"},"reserve-commit-rollback")," operations: if the consumer crashes between\n",(0,o.kt)("inlineCode",{parentName:"p"},"reserve")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"commit")," the element will eventually be auto-rolledback and be processed again (possibly by another consumer).\nTherefore, duplications are tolerated but losses are not"),(0,o.kt)("mermaid",{parentName:"li",value:"sequenceDiagram\n  autonumber\n  participant queue\n  participant consumer\n  consumer->>+queue: reserve\n  queue->>-consumer: element\n  activate consumer\n  note left of queue: element is still in queue, but not accesible to other consumers\n  note right of consumer: process element\n  consumer->>-queue: commit\n  activate queue\n  queue->>consumer: ack\n  deactivate queue\n  note left of queue: element is no longer in queue\n  note right of consumer: element processed, get another\n  consumer->>+queue: pop\n  queue->>-consumer: element"})),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"exactly-once")),": theoretical consumer guarantee where no losses and no duplications can happen. It involves the use ot monotonical\nidentifiers or window-based duplication detection, and is generally extremelly complex to achieve, and almost in all cases with a\nhefty performance penalty. It is almost never offered out fo the box in any QMW")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"deadletter queue")),": usually, there is a maximum number of times an element can be rolled back after a reserve, in order to prevent\nill-formed or otherwise incorrect messages to stay forever in queues. Upon rollback, if the element has reached the maximum number of\nrollbacks it is remove from the queue and pushed into the deadletter queue, which is an otherwise regular queue")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"ordered queue")),":  A non-FIFO queue: insertions are not done at the tail of the queue, but at any point. This means insertions are\nno longer ",(0,o.kt)("em",{parentName:"p"},"O(1)"),": depending on the technology used they can be ",(0,o.kt)("em",{parentName:"p"},"O(n"),") or better, such as ",(0,o.kt)("em",{parentName:"p"},"O(log(n))")," for a btree-based queue; same goes for\npush/reserve operations, they are no longer ",(0,o.kt)("em",{parentName:"p"},"O(1)"),"."),(0,o.kt)("p",{parentName:"li"},"Using ordered queues on a QMW is key to implement certain operations: not only the more obvious such as delay, schedule or priorities,\nbut also robust and performing reserve/commit/rollback"),(0,o.kt)("p",{parentName:"li"},"Using a database to implement queues makes ordered queues a bliss: using a regular index is usually all you need to get\nnear-constant-complexity operations")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"delay/schedule")),": Push operation when the element is marked to not to be elligible for pop or reserve ",(0,o.kt)("em",{parentName:"p"},"before")," a certain time.\nThe presence of delayed elements must not impact in any way the rest of elements (that is, the rest of elements' elligibility must not\nchange) or the queue itself (that is, que presence of delayed elements must not degrade the queue performance or capabilities)"),(0,o.kt)("p",{parentName:"li"},"This feature can be very easily implemented using an ordered queue, where the order is defined by a timestamp representing the\n",(0,o.kt)("em",{parentName:"p"},"mature")," time: the time when the element can be popped or reserved, and not before"),(0,o.kt)("p",{parentName:"li"},"The delay/schedule feature can be applied also to rollbacks, since a rollback is conceptually a re-insertion; delays in rollbacks\nprovide a way to implement ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Exponential_backoff"},"exponential backoff")," easily, to prevent busy\nreserve-fail-rollback loops when only one element is in the queue, and the element is repeteadly rolled back upon processing"))),(0,o.kt)("h2",{id:"basic-building-blocks"},"Basic building blocks"),(0,o.kt)("p",null,"Here's what you need to build a proper QMW:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"A ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"storage subsystem")),": Data for the contents of the queues have to be stored somewhere. It has to provide:"),(0,o.kt)("ol",{parentName:"li"},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"Persistency"),": data must be stored in a permanent manner, realiably. In-memory QMW has its niche, but we will\nfocus on ",(0,o.kt)("em",{parentName:"li"},"persistent")," QMWs"),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"High Availability"),": we do not want a hardware or network failure to take down the QMW. It should run in a ",(0,o.kt)("em",{parentName:"li"},"cluster"),"\nmanner, on several machines (possibly in separated geographical locations); if one of the machines fail the rest\ncan cope without (or with minimal) disruption"),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"Sufficient Throughput"),": the storage should be able to handle a high number of operations per second"),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("strong",{parentName:"li"},"Low Latency"),": operations should be performed very fast, ideally as independent of throughput as possible"))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"An ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("em",{parentName:"strong"},"event bus")),": all QMW clients would need some form of central communication to be aware of certain events in the\nQWM. For example, if a client is waiting for data to become available in a queue, it should be able to simply await for\nan event, instead of running a poll busy-loop. Another example  of useful event is to signal whether a queue becomes\npaused (since it must be paused for ",(0,o.kt)("em",{parentName:"p"},"all")," clients)"),(0,o.kt)("p",{parentName:"li"},"This event bus can be a ",(0,o.kt)("em",{parentName:"p"},"pub/sub"),", stateless bus: only connected clients are made aware of events and there is no need to save\nevents for clients that may connect later. This simplifies the event bus by a lot."))),(0,o.kt)("p",null,"The whole idea behind ",(0,o.kt)("inlineCode",{parentName:"p"},"keuss")," is that all those building blocks are already available out there in the form of DataBase\nsystems, and all there is to add is a thin layer and a few extras."),(0,o.kt)("h2",{id:"the-need-for-atomic-operations"},"The need for atomic operations"),(0,o.kt)("p",null,"However, not just ",(0,o.kt)("em",{parentName:"p"},"any")," storage (or DB, for that matter) is a good candidate to model queues: there is at least one feature\nthat, lest it be present, renders queue modelling very difficult if not impossible: ",(0,o.kt)("em",{parentName:"p"},"atomic modify operations")),(0,o.kt)("p",null,"An atomic modify operation in the context of a storage system can be defined as the ability to perform a read and a modify\non a single record without the possibility of a second modify interfering, changing the record after the read but before\nthe modify (or after the modify and before the read)"),(0,o.kt)("p",null,"If the storage system provides such primitives, it is relatively easy and simple to model queues on top of it; also, the\noverall performance (throughput and latency) will greatly depend on the performance of such operation: most RDBMs can do\nthis by packing the read and the modify inside a ",(0,o.kt)("em",{parentName:"p"},"transaction"),", but that usually degrades the performance greatly, to a\npoint where it is not viable for queue modelling"),(0,o.kt)("p",null,"There are 2 major storage systems that provide all the needed blocks, along with atomic modifies: ",(0,o.kt)("inlineCode",{parentName:"p"},"MongoDB")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"Redis"),".\n",(0,o.kt)("inlineCode",{parentName:"p"},"MongoDB")," has turned out to be an almost perfect fit to back a QMW, as we shall see. ",(0,o.kt)("inlineCode",{parentName:"p"},"MongoDB")," provides a set of atomic\noperations to read and modify, and to read and remove. Those operations guarantee that the elements selected to be read\nand then modified (or removed) will not be read by others until modified (or not read at all if it's removed)"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"Redis")," is also a good fit, but it does nor provide a good enough storage layer: it is neither persistent nor high available.\nArguably, that's a default behaviour: ",(0,o.kt)("inlineCode",{parentName:"p"},"Redis-Cluster")," coupled with proper persistency should in theory be up to the task.\nHowever, this series of articles would focus on ",(0,o.kt)("inlineCode",{parentName:"p"},"MongoDB")," only. For now, let us say that atomic operations are very easily\nadded to ",(0,o.kt)("inlineCode",{parentName:"p"},"Redis")," by coding them as ",(0,o.kt)("inlineCode",{parentName:"p"},"lua")," extensions, since all operations in ",(0,o.kt)("inlineCode",{parentName:"p"},"Redis")," are atomic by design"),(0,o.kt)("p",null,"In the following sections we will see how the implementations of common QMW operations can be indeed solved elegently using\natomic operations provided by MongoDB as the underlying DB/storage"),(0,o.kt)("h2",{id:"simple-approach-good-enough-queues"},"Simple approach: good enough queues"),(0,o.kt)("p",null,"There is a very simple, very common way to model queues on top of mongoDB collections. This model does not support\nreserve-commit-rollback, nor it does support delay/schedule. The model can be succintly put as:"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:"center"},"operation"),(0,o.kt)("th",{parentName:"tr",align:"center"},"implementation base"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:"center"},"push"),(0,o.kt)("td",{parentName:"tr",align:"center"},(0,o.kt)("inlineCode",{parentName:"td"},"coll.insertOne (item)"))),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:"center"},"pop"),(0,o.kt)("td",{parentName:"tr",align:"center"},(0,o.kt)("inlineCode",{parentName:"td"},"coll.findOneAndDelete()"))))),(0,o.kt)("p",null,"The key is the use of the atomic operation ",(0,o.kt)("inlineCode",{parentName:"p"},"findOneAndDelete"),", which is the combination of a ",(0,o.kt)("inlineCode",{parentName:"p"},"findOne")," and a ",(0,o.kt)("inlineCode",{parentName:"p"},"remove"),", but\nrun in one single step. Several actors can perform concurrent ",(0,o.kt)("inlineCode",{parentName:"p"},"findOneAndDelete")," operations without issues, and without\ninterfering each other"),(0,o.kt)("p",null,"Actors can perform concurrent ",(0,o.kt)("inlineCode",{parentName:"p"},"insertOne")," operations too, without interference; the same goes for actors performing ",(0,o.kt)("em",{parentName:"p"},"both"),"\n",(0,o.kt)("inlineCode",{parentName:"p"},"findOneAndDelete")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"insertOne")," operations. The net result is that many consumers and producers can be served concurrently\nwithout interferences or loss of performance, which is what one expects of any self-respecting QMW"),(0,o.kt)("p",null,"This model provides a very simple but rather capable powerful QMW:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"queues are ",(0,o.kt)("em",{parentName:"li"},"mostly")," strict FIFO (FIFO loses its strict meaning when different producers located in different machines\nare inserting in the same queue, but in practical terms it usually does not matter)"),(0,o.kt)("li",{parentName:"ul"},"we got very good persistence, as good as mongodb's"),(0,o.kt)("li",{parentName:"ul"},"we got very good HA:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"both consumers and producers have no state, so they can be replicated without problems"),(0,o.kt)("li",{parentName:"ul"},"there is a practical 1:1 equivalence between queues and collections, so all the HA guarantees mongodb provides on\ncollections apply directly to queues"))),(0,o.kt)("li",{parentName:"ul"},"we got more than decent performance:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"mongodb is quite performing on insertions, in the range of Khz (ie, thousands per second)"),(0,o.kt)("li",{parentName:"ul"},"on pop operations, ",(0,o.kt)("inlineCode",{parentName:"li"},"findOneAndDelete")," is less performing than a simple ",(0,o.kt)("inlineCode",{parentName:"li"},"remove")," or a ",(0,o.kt)("inlineCode",{parentName:"li"},"findOne")," but is still able to\nreach Khz performance. In practice, ",(0,o.kt)("inlineCode",{parentName:"li"},"findOneAndDelete")," is the bottleneck of this model, because it serializes calls\nto ",(0,o.kt)("inlineCode",{parentName:"li"},"pop")," within each queue")))),(0,o.kt)("p",null,"The main drawback of this model is the fact that the pop/reserve operations can only be performed in a poll loop: they\neither return an element or return 'no elements in queue' (or return an error), in all cases pretty mich immediately.\nTherefore, wait state of arbitrary duration must be inserted in the consumer loop if the operation returns 'no elements in queue':\notherwise you will get a busy loop where your pop/reserve call relentlessly return 'no elements', eating the CPU in the\nprocess (incidentally, this is a text-book case of poll loop)"),(0,o.kt)("p",null,"In some cases, where latencies in the range of seconds or tens of seconds are of no concern, a pool loop can be happily\nused, so this makes a valid, simple and effective model, especially if you already use MongoDB. In cases where latencies\nare expected to be near-realtime something better is needed"),(0,o.kt)("h2",{id:"adding-an-event-bus"},"Adding an event bus"),(0,o.kt)("p",null,"At this point, one of the best improvements to the model is to remove the need for poll loops; for that to happen, we\nneed the pop/reserve operations to 'block' if there are no elements, until they are. A na\xefve way to do so is to add the\npoll loop in the pop/reserve calls, so the caller would have the ",(0,o.kt)("em",{parentName:"p"},"illusion")," of blocking:"),(0,o.kt)("mermaid",{value:"sequenceDiagram\n  autonumber\n  participant queue\n  participant consumer\n  participant caller\n  caller->>consumer: pop\n  consumer->>queue: pop\n  queue->>consumer: no elements\n  note right of consumer: wait a fixed period, then try again\n  consumer->>queue: pop\n  queue->>consumer: no elements\n  note right of consumer: wait a fixed period, then try again\n  note left of queue: someone else inserts at least one element\n  consumer->>queue: pop\n  queue->>consumer: element\n  consumer->> caller: element"}),(0,o.kt)("p",null,"As mentioned, this simply moves the pool loop inside the pop/reserve implemenation, away from the user's eyes. But it\nis still a poll loop, with all its limitations. To truly remove the poll loop we need the ability to ",(0,o.kt)("em",{parentName:"p"},"wake up")," a waiting\nconsumer ",(0,o.kt)("em",{parentName:"p"},"when")," there are new elements in the queue:"),(0,o.kt)("mermaid",{value:"sequenceDiagram\n  autonumber\n  participant producer\n  participant queue\n  participant consumer\n  participant caller\n  caller->>consumer: pop\n  consumer->>queue: pop\n  queue->>consumer: no elements\n  note right of consumer: wait until woken up\n  producer->>queue: push\n  note right of queue: now we got elements\n  queue--\x3e>consumer: wake-up, elements available \n  consumer->>queue: pop\n  queue->>consumer: element\n  consumer->> caller: element"}),(0,o.kt)("p",null,"This way the push-to-pop latencies are reduced to close to the theoretical minimum: any consumer would be blocked only when\nthey have to: when there are no elements"),(0,o.kt)("h3",{id:"possible-implementations"},"Possible implementations"),(0,o.kt)("p",null,"There is an obvious option for the implementation of such an event bus: a pub/sub subsystem. Pub/sub is very well understood,\nit's stateless and there are a lot of stable implementations. And more importantly, there are stable implementations ",(0,o.kt)("em",{parentName:"p"},"on top"),"\nof we already use for storage of queues."),(0,o.kt)("p",null,"The main disadvantages of pub/sub in themselves as event bus are:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"they can not handle duplicates: in an HA setup all the replicas of a given client will get a separated copy of each event"),(0,o.kt)("li",{parentName:"ul"},"they have no history: disconnected clients will miss any event published when they're not connected")),(0,o.kt)("p",null,"But none of those is a real disadvantage for us:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"each client, whether a replica or not, ",(0,o.kt)("em",{parentName:"li"},"must")," receive a copy of each event"),(0,o.kt)("li",{parentName:"ul"},"disconnected clients do not need to receive and react to events, since they're not dealing with queues")),(0,o.kt)("p",null,"Let's see the most viable implementations:"),(0,o.kt)("h4",{id:"in-memory-pubsub"},"In-memory pub/sub"),(0,o.kt)("p",null,"This is a very simple, extremely nimbre implementation of a pub/sub that works only within the same (OS) process. It's only\nmeant to be used for testing. It can be also seen as the ",(0,o.kt)("em",{parentName:"p"},"canonical")," implementation of the event bus"),(0,o.kt)("p",null,"A very good and very simple implementation for node.js is ",(0,o.kt)("a",{parentName:"p",href:"https://www.npmjs.com/package/mitt"},"mitt")),(0,o.kt)("h4",{id:"redis-pubsub"},"Redis pub/sub"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"redis")," offers a simple and very efficient ",(0,o.kt)("a",{parentName:"p",href:"https://redis.io/docs/manual/pubsub/"},"pub/sub implementation"),", which can be used\nas is. If you already use redis it's definitely the way to go"),(0,o.kt)("h4",{id:"mongodb-capped-collection-also-a-pubsub"},"MongoDB capped collection (also a pub/sub)"),(0,o.kt)("p",null,"Since ",(0,o.kt)("inlineCode",{parentName:"p"},"mongoDB")," is used to back the queues, it would be great if it could also power the rest of the needed subsystems; and it does,\nwith a just a little implementation work: it is relatively easy to build a pubsub on top of\n",(0,o.kt)("a",{parentName:"p",href:"https://www.mongodb.com/docs/upcoming/core/capped-collections/"},"mongoDB capped collections"),", and there are quite a few\nimplementations readily available. One good example of such implementation in node.js is ",(0,o.kt)("a",{parentName:"p",href:"https://www.npmjs.com/package/@nodebb/mubsub"},"mubsub")),(0,o.kt)("p",null,"Using this implementation has the added appeal of not adding any extra dependency: you can just use the same mongoDB server used for\nthe queues"),(0,o.kt)("p",null,"This implementations has the added benefit of ",(0,o.kt)("em",{parentName:"p"},"history state"),": it operates like a ring buffer, so there is the possibility of\naccessing past events. However, this is not needed at all here"),(0,o.kt)("h3",{id:"practical-considerations--improvements"},"Practical considerations & improvements"),(0,o.kt)("p",null,"There are a few considerations worth noting about how pubsub fits our purpose, and a few extras we can add to improve matters further"),(0,o.kt)("h4",{id:"race-conditions"},"Race conditions"),(0,o.kt)("p",null,"A pubsub bus is asynchronous in nature, so under some conditions you may lose events. Take for example the case of a single client\nthat reinserts an element in the same queue it is consuming from: the event fired upon the insertion is produced at about the same time\nthe client attempts to pop another element. However, if the pop operation establishes the queue is empty (because the queue size was\nnot yet updated after the insert) but the event arrives before the pop operation starts waiting for them, you lose the event and you\nrisk waiting forever, when the queue has indeed one element"),(0,o.kt)("mermaid",{value:"  sequenceDiagram\n    autonumber\n    participant queue\n    participant consumer\n    consumer->>queue: pop\n    queue->>consumer: element\n    consumer->>queue: push a new element\n    queue--\x3e>consumer: wake-up, elements available \n    consumer->>queue: pop\n    note right of consumer: it might see the queue empty\n    note right of consumer: it might lose the wake-up event\n    note left of queue: waits indefinitely"}),(0,o.kt)("p",null,"Race conditions such as this one are very hard to prevent entirely, if at all possible. For that reason it is recommended to use\na model in which race conditions do not cause major issues"),(0,o.kt)("p",null,"In a system such as a ",(0,o.kt)("inlineCode",{parentName:"p"},"QMW")," the problems to avoid at all costs are:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"loss of messages"),(0,o.kt)("li",{parentName:"ul"},"duplication of messages"),(0,o.kt)("li",{parentName:"ul"},"deadlocks and other forms of wait-forever conditions")),(0,o.kt)("p",null,"Race conditions on wake-up events won't cause loss or duplications of messages, since this is guaranteed by the queue model; they can\nhowever cause deadlocks, where a consumer is left waiting forever for an event that may never arrive"),(0,o.kt)("p",null,"One way to remove this problem is to add a timeout and a poll loop: in the absence of events, the consumer will fallback into a poll\nloop with a rather long period (this period would be the wait-for-events timeout), usually in the range of tens of seconds. With this\nwe change deadlocks into poll cycles, or deadlocks into increased latency for some rare cases"),(0,o.kt)("p",null,"The consume pop loop would look like this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"forever do:\n  msg := pop_msg_from_queue()  // nonblocking operation, either returns a message or null if none available\n  if (!msg) do:\n    await wake_up(insertion) or timeout(period)\n    continue // a wakeup event arrived or the the timeout was reached: next loop either way\n  else\n    return msg\n  done\ndone\n")),(0,o.kt)("h4",{id:"high-cardinality-of-events"},"High cardinality of events"),(0,o.kt)("p",null,"A side effect of having 'insert' events published is that subscribers must be ready to deal with potentially enormous amounts of events;\nif you're inserting messages in queues at, say 1 Khz and you have 50 consumers, you will have 50,000 individual events to deal with.\nBesides, most of thos events will add no information at all: once a consumer is woken up, it would not be interested in insert events until the queue is empty again; queue consumers jsut ignore events emitted when they are not idle, but the raw amount of events in the\nbus might still need a noticeable amount of compute and I/O (especially on non-local pubsubs)"),(0,o.kt)("p",null,"A simple way to minimize this is to simply ignore events if an equivalent one was emitted already in a short period of time; if that is\nthe case, the event is ignored right before the publish, and does not make it to the pubsub at all"),(0,o.kt)("p",null,"Keuss uses exactly this strategy on all the included signal pubsubs, using a window of 50 ms: if the same event was emitted for the same queue within 50 ms in the past, it is ignored"),(0,o.kt)("h5",{id:"drawbacks"},"Drawbacks"),(0,o.kt)("p",null,"This strategy has a notable drawback: it introduces an apparent race condition. "),(0,o.kt)("p",null,"Take a queue with a single consumer; insert a single message in the queue, which would be immediately taken by the consumer. If the\nconsumer rejects the message with a zero delay, the consumer may still see zero elements in the next iteration, so it'll block and\nwait for insert events. The reject will indeed produce an insert event... which will be dropped because it's equivalene to the first\ninsert event, that was emitted about the same millsecond"),(0,o.kt)("p",null,"This will just be a nuisance, since the consumer would time out and rearm itself eventually. But be warned, this can happen on edge\ncases"),(0,o.kt)("h4",{id:"adding-another-pubsub-implementation"},"Adding another pub/sub implementation"),(0,o.kt)("p",null,"The interface for pubsub in Keuss is very simple, so adding new or different implementations would be quite easy. For example, if\nyou already use ",(0,o.kt)("inlineCode",{parentName:"p"},"mqtt"),", it makes sense to reuse it to power the event pubsub. This is however out of scope"),(0,o.kt)("h3",{id:"final-thoughts"},"Final thoughts"),(0,o.kt)("p",null,"At this point we got a rather decent QMW capable of push/pop with concurrent pubishers and consumers, with persistence and HA, and\nable to manage operations at Khz frequency with millisec latencies; all this with a quite simple and stateless implementation"),(0,o.kt)("p",null,"This model can already solve a great deal of problems where persistent job queues are needed, especially if you already got MongoDB\nin your mix. Also, it has 2 advantages over tradicional QMWs :"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("em",{parentName:"li"},"Performance"),": This model produces great performance figures when compared with tradicional QMWs with full persistence/HA activated"),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("em",{parentName:"li"},"Simplicity"),": the whole of the implementation is client side, and it is stateless and very thin. "),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("em",{parentName:"li"},"Ease of debug"),": it is very easy to ",(0,o.kt)("em",{parentName:"li"},"open the trunk"),", peek inside and see exactly what's in each queue, and it equally easy to tweak\nand fix whatever problem you find. In some situations this is an invaluable feature")),(0,o.kt)("p",null,"However, we can ",(0,o.kt)("a",{parentName:"p",href:"/blog/2024/01/23/queues-on-mongo-part-2"},"do better"),"..."))}m.isMDXComponent=!0}}]);