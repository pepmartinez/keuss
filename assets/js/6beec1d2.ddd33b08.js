"use strict";(self.webpackChunkkeuss_docusaurus=self.webpackChunkkeuss_docusaurus||[]).push([[38],{3905:function(e,t,n){n.d(t,{Zo:function(){return d},kt:function(){return m}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),u=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=u(n),m=o,k=p["".concat(l,".").concat(m)]||p[m]||c[m]||r;return n?a.createElement(k,i(i({ref:t},d),{},{components:n})):a.createElement(k,i({ref:t},d))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var u=2;u<r;u++)i[u]=n[u];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},8682:function(e,t,n){n.r(t),n.d(t,{assets:function(){return d},contentTitle:function(){return l},default:function(){return m},frontMatter:function(){return s},metadata:function(){return u},toc:function(){return c}});var a=n(3117),o=n(102),r=(n(7294),n(3905)),i=["components"],s={id:"buckets",title:"Bucket-based backends",sidebar_label:"Bucket-based backends"},l=void 0,u={unversionedId:"usage/buckets",id:"usage/buckets",title:"Bucket-based backends",description:"Up to version 1.4.X all backends worked in the same way, one element at a time: pushing and popping elements fired one or more operations per element on the underlying storage. This means the bottleneck would end up being the storage's I/O; redis and mongo both allow quite high I/O rates, enough to work at thousands of operations per second. Still, the limit was there.",source:"@site/docs/usage/buckets.md",sourceDirName:"usage",slug:"/usage/buckets",permalink:"/keuss/docs/usage/buckets",editUrl:"https://github.com/pepmartinez/keuss/edit/master/website/docs/usage/buckets.md",tags:[],version:"current",frontMatter:{id:"buckets",title:"Bucket-based backends",sidebar_label:"Bucket-based backends"},sidebar:"someSidebar",previous:{title:"Putting all together",permalink:"/keuss/docs/usage/putting-all-together"},next:{title:"Shutdown",permalink:"/keuss/docs/usage/shutdown"}},d={},c=[{value:"bucket-mongo-safe",id:"bucket-mongo-safe",level:3},{value:"bucket-mongo",id:"bucket-mongo",level:3}],p={toc:c};function m(e){var t=e.components,n=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Up to version 1.4.X all backends worked in the same way, one element at a time: pushing and popping elements fired one or more operations per element on the underlying storage. This means the bottleneck would end up being the storage's I/O; redis and mongo both allow quite high I/O rates, enough to work at thousands of operations per second. Still, the limit was there."),(0,r.kt)("p",null,"Starting with v1.5.2 keuss includes 2 backends that do not share this limitation: they work by packing many elements inside a single 'storage unit'. Sure enough, this adds some complexity and extra risks, but the throughput improvement is staggering: on mongodb it goes from 3-4 Ktps to 35-40Ktps, and the bottleneck shifted from mongod to the client's cpu, busy serializing and deserializing payloads."),(0,r.kt)("p",null,"Two bucked-based backends were added, both based on mongodb: ",(0,r.kt)("a",{parentName:"p",href:"#bucket-mongo"},"bucket-mongo")," and ",(0,r.kt)("a",{parentName:"p",href:"#bucket-mongo-safe"},"bucket-mongo-safe"),". Both are usable, but there is little gain on using fhe first over the second: ",(0,r.kt)("inlineCode",{parentName:"p"},"bucket-mongo")," was used as a prototyping area, and although perfectly usable, it turned out ",(0,r.kt)("inlineCode",{parentName:"p"},"bucket-mongo-safe")," is better in almost every aspect: it provides better guarantees and more features, at about the same performance."),(0,r.kt)("h3",{id:"bucket-mongo-safe"},"bucket-mongo-safe"),(0,r.kt)("p",null,"In addition to the general options, the factory accepts the following extra options:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"bucket_max_size"),": maximum number of elements in a bucket, defaults to 1024"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"bucket_max_wait"),": milliseconds to wait before flushing a push bucket: pushes are buffered in a push bucket, which are flushed when they're full (reach ",(0,r.kt)("inlineCode",{parentName:"li"},"bucket_max_size")," elements). If this amount of millisecs go by and the push bucket is not yet full, it is flushed as is. Defaults to 500."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"reserve_delay"),": number of seconds a bucket keeps its 'reserved' status when read from mongodb. Defaults to 30."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"state_flush_period"),": changes in state on each active/read bucket are flushed to mongodb every those milliseconds. Defaults to 500."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"reject_delta_base"),", ",(0,r.kt)("inlineCode",{parentName:"li"},"reject_delta_factor"),": if no call to ",(0,r.kt)("inlineCode",{parentName:"li"},"ko")," provide a ",(0,r.kt)("inlineCode",{parentName:"li"},"next_t"),", the backend will set one using a simple grade-1 polynom, in the form of ",(0,r.kt)("inlineCode",{parentName:"li"},"reject_delta_factor * tries + reject_delta_base"),", in millisecs. They default to ",(0,r.kt)("inlineCode",{parentName:"li"},"10000")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"((reserve_delay * 1000) || 30000)")," respectively"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"reject_timeout_grace"),": number of seconds to wait since a bucket is reserved/read until it is considered timed out; after this, what is left of the bucket is rejected/retried. Defaults to (",(0,r.kt)("inlineCode",{parentName:"li"},"reserve_delay")," * ",(0,r.kt)("inlineCode",{parentName:"li"},"0.8"),")"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"state_flush_period"),": flush intermediate state changes in each active read bucked every this amount of millisecs")),(0,r.kt)("p",null,"Bucket-mongo-safe works by packing many payloads in a single mongodb object:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"At ",(0,r.kt)("inlineCode",{parentName:"li"},"push()")," time, objects are buffered in memory and pushed (inserted) only when bucket_max_size has been reached or when a bucket has been getting filled for longer than bucket_max_wait millisecs."),(0,r.kt)("li",{parentName:"ul"},"At ",(0,r.kt)("inlineCode",{parentName:"li"},"pop/reserve")," time full objects are read into mem, and then individual payloads returned from there. Both commits and pops are just marked in memory and then flushed every state_flush_period millisecs, or when the bucked is exhausted."),(0,r.kt)("li",{parentName:"ul"},"Buckets remain unmodified since they are created in terms of the payloads they contain: a ",(0,r.kt)("inlineCode",{parentName:"li"},"pop()")," or ",(0,r.kt)("inlineCode",{parentName:"li"},"ko/ok")," would only mark payloads inside buckets as read/not-anymore-available, but buckets are never splitted nor merged.")),(0,r.kt)("p",null,"Thus, it is important to call ",(0,r.kt)("inlineCode",{parentName:"p"},"drain()")," on queues of this backend: this call ensures all pending write buckets are interted in mongodb, and also ensures all in-memory buckets left are completely read (served through pop/reserve)."),(0,r.kt)("p",null,"Also, there is little difference in performance and I/O between ",(0,r.kt)("inlineCode",{parentName:"p"},"pop")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"reserve/commit"),"; performance is no longer a reason to prefer one over the other."),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Scheduling on ",(0,r.kt)("inlineCode",{parentName:"p"},"bucket-mongo-safe")," is perfectly possible, but with a twist: the effective ",(0,r.kt)("inlineCode",{parentName:"p"},"mature_t")," of a message will be the oldest in the whole bucket it resides in. This applies to both insert and rollback/ko. In practice this is usually not a big deal, since anyway the ",(0,r.kt)("inlineCode",{parentName:"p"},"mature_t")," is a 'not before' time, and that's all Keuss (or any other queuing middleware) would guarantee."))),(0,r.kt)("h3",{id:"bucket-mongo"},"bucket-mongo"),(0,r.kt)("p",null,"This is a simpler version of buckets-on-mongodb, and for all purposes ",(0,r.kt)("inlineCode",{parentName:"p"},"bucket-mongo-safe")," should be preferred; it does not provide reserve, nor schedule. It is however a tad faster and lighter on I/O."),(0,r.kt)("p",null,"It is provided only for historical and educational purposes."))}m.isMDXComponent=!0}}]);