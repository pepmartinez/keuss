"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[807],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),u=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=u(n),m=o,k=p["".concat(l,".").concat(m)]||p[m]||c[m]||i;return n?a.createElement(k,r(r({ref:t},d),{},{components:n})):a.createElement(k,r({ref:t},d))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,r[1]=s;for(var u=2;u<i;u++)r[u]=n[u];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},4661:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>i,metadata:()=>s,toc:()=>u});var a=n(7462),o=(n(7294),n(3905));const i={id:"buckets",title:"Bucket-based backends",sidebar_label:"Bucket-based backends"},r=void 0,s={unversionedId:"usage/buckets",id:"usage/buckets",title:"Bucket-based backends",description:"Up to version 1.4.X all backends worked in the same way, one element at a time: pushing and popping elements fired one or more operations per element on the underlying storage. This means the bottleneck would end up being the storage's I/O; redis and mongo both allow quite high I/O rates, enough to work at thousands of operations per second. Still, the limit was there.",source:"@site/docs/04-usage/05-buckets.md",sourceDirName:"04-usage",slug:"/usage/buckets",permalink:"/keuss/docs/usage/buckets",draft:!1,editUrl:"https://github.com/pepmartinez/keuss/edit/master/website/docs/04-usage/05-buckets.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{id:"buckets",title:"Bucket-based backends",sidebar_label:"Bucket-based backends"},sidebar:"tutorialSidebar",previous:{title:"Using no signaller",permalink:"/keuss/docs/usage/no-signaller"},next:{title:"About",permalink:"/keuss/docs/usage/pipelines/about"}},l={},u=[{value:"bucket-mongo-safe",id:"bucket-mongo-safe",level:3},{value:"bucket-mongo",id:"bucket-mongo",level:3}],d={toc:u};function c(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Up to version 1.4.X all backends worked in the same way, one element at a time: pushing and popping elements fired one or more operations per element on the underlying storage. This means the bottleneck would end up being the storage's I/O; redis and mongo both allow quite high I/O rates, enough to work at thousands of operations per second. Still, the limit was there."),(0,o.kt)("p",null,"Starting with v1.5.2 keuss includes 2 backends that do not share this limitation: they work by packing many elements inside a single 'storage unit'. Sure enough, this adds some complexity and extra risks, but the throughput improvement is staggering: on mongodb it goes from 3-4 Ktps to 35-40Ktps, and the bottleneck shifted from mongod to the client's cpu, busy serializing and deserializing payloads."),(0,o.kt)("p",null,"Two bucked-based backends were added, both based on mongodb: ",(0,o.kt)("a",{parentName:"p",href:"#bucket-mongo"},"bucket-mongo")," and ",(0,o.kt)("a",{parentName:"p",href:"#bucket-mongo-safe"},"bucket-mongo-safe"),". Both are usable, but there is little gain on using fhe first over the second: ",(0,o.kt)("inlineCode",{parentName:"p"},"bucket-mongo")," was used as a prototyping area, and although perfectly usable, it turned out ",(0,o.kt)("inlineCode",{parentName:"p"},"bucket-mongo-safe")," is better in almost every aspect: it provides better guarantees and more features, at about the same performance."),(0,o.kt)("h3",{id:"bucket-mongo-safe"},"bucket-mongo-safe"),(0,o.kt)("p",null,"In addition to the general options, the factory accepts the following extra options:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"bucket_max_size"),": maximum number of elements in a bucket, defaults to 1024"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"bucket_max_wait"),": milliseconds to wait before flushing a push bucket: pushes are buffered in a push bucket, which are flushed when they're full (reach ",(0,o.kt)("inlineCode",{parentName:"li"},"bucket_max_size")," elements). If this amount of millisecs go by and the push bucket is not yet full, it is flushed as is. Defaults to 500."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"state_flush_period"),": changes in state on each active/read bucket are flushed to mongodb every those milliseconds. Defaults to 500."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"reject_delta_base"),", ",(0,o.kt)("inlineCode",{parentName:"li"},"reject_delta_factor"),": if no call to ",(0,o.kt)("inlineCode",{parentName:"li"},"ko")," provide a ",(0,o.kt)("inlineCode",{parentName:"li"},"next_t"),", the backend will set one using a simple grade-1 polynom, in the form of ",(0,o.kt)("inlineCode",{parentName:"li"},"reject_delta_factor * tries + reject_delta_base"),", in millisecs. They default to ",(0,o.kt)("inlineCode",{parentName:"li"},"10000")," and ",(0,o.kt)("inlineCode",{parentName:"li"},"((reserve_delay * 1000) || 30000)")," respectively"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"reject_timeout_grace"),": number of seconds to wait since a bucket is reserved/read until it is considered timed out; after this, what is left of the bucket is rejected/retried. Defaults to (",(0,o.kt)("inlineCode",{parentName:"li"},"reserve_delay")," * ",(0,o.kt)("inlineCode",{parentName:"li"},"0.8"),")"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"state_flush_period"),": flush intermediate state changes in each active read bucked every this amount of millisecs")),(0,o.kt)("p",null,"Bucket-mongo-safe works by packing many payloads in a single mongodb object:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"At ",(0,o.kt)("inlineCode",{parentName:"li"},"push()")," time, objects are buffered in memory and pushed (inserted) only when bucket_max_size has been reached or when a bucket has been getting filled for longer than bucket_max_wait millisecs."),(0,o.kt)("li",{parentName:"ul"},"At ",(0,o.kt)("inlineCode",{parentName:"li"},"pop/reserve")," time full objects are read into mem, and then individual payloads returned from there. Both commits and pops are just marked in memory and then flushed every state_flush_period millisecs, or when the bucked is exhausted."),(0,o.kt)("li",{parentName:"ul"},"Buckets remain unmodified since they are created in terms of the payloads they contain: a ",(0,o.kt)("inlineCode",{parentName:"li"},"pop()")," or ",(0,o.kt)("inlineCode",{parentName:"li"},"ko/ok")," would only mark payloads inside buckets as read/not-anymore-available, but buckets are never splitted nor merged.")),(0,o.kt)("p",null,"Thus, it is important to call ",(0,o.kt)("inlineCode",{parentName:"p"},"drain()")," on queues of this backend: this call ensures all pending write buckets are interted in mongodb, and also ensures all in-memory buckets left are completely read (served through pop/reserve)."),(0,o.kt)("p",null,"Also, there is little difference in performance and I/O between ",(0,o.kt)("inlineCode",{parentName:"p"},"pop")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"reserve/commit"),"; performance is no longer a reason to prefer one over the other."),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Scheduling on ",(0,o.kt)("inlineCode",{parentName:"p"},"bucket-mongo-safe")," is perfectly possible, but with a twist: the effective ",(0,o.kt)("inlineCode",{parentName:"p"},"mature_t")," of a message will be the oldest in the whole bucket it resides in. This applies to both insert and rollback/ko. In practice this is usually not a big deal, since anyway the ",(0,o.kt)("inlineCode",{parentName:"p"},"mature_t")," is a 'not before' time, and that's all Keuss (or any other queuing middleware) would guarantee.")),(0,o.kt)("h3",{id:"bucket-mongo"},"bucket-mongo"),(0,o.kt)("p",null,"This is a simpler version of buckets-on-mongodb, and for all purposes ",(0,o.kt)("inlineCode",{parentName:"p"},"bucket-mongo-safe")," should be preferred; it does not provide reserve, nor schedule. It is however a tad faster and lighter on I/O."),(0,o.kt)("p",null,"It is provided only for historical and educational purposes."))}c.isMDXComponent=!0}}]);